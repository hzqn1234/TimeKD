{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9fd263f-0f92-490b-b8ce-5a67f3f6e8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        scaler,\n",
    "        channel,\n",
    "        num_nodes,\n",
    "        seq_len,\n",
    "        pred_len,\n",
    "        dropout_n,\n",
    "        d_llm,\n",
    "        e_layer,\n",
    "        head,\n",
    "        lrate,\n",
    "        wdecay,\n",
    "        feature_w,\n",
    "        fcst_w,\n",
    "        recon_w,\n",
    "        att_w,\n",
    "        device,\n",
    "        epochs\n",
    "    ):\n",
    "        self.model = Dual(\n",
    "            device=device, channel=channel, num_nodes=num_nodes, seq_len=seq_len, pred_len=pred_len, \n",
    "            dropout_n=dropout_n, d_llm=d_llm, e_layer=e_layer, head=head\n",
    "        )\n",
    "        \n",
    "        self.optimizer = optim.AdamW(self.model.parameters(), lr=lrate, weight_decay=wdecay)\n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=min(epochs, 100), eta_min=1e-8, verbose=True)\n",
    "        self.MSE = MSE\n",
    "        self.MAE = MAE\n",
    "        self.clip = 5\n",
    "        self.scaler = scaler\n",
    "        self.device = device\n",
    "\n",
    "        self.feature_loss = 'smooth_l1'  \n",
    "        self.fcst_loss = 'smooth_l1'\n",
    "        self.recon_loss = 'smooth_l1'\n",
    "        self.att_loss = 'smooth_l1'   \n",
    "        self.fcst_w = 1\n",
    "        self.recon_w = 0.5\n",
    "        self.feature_w = 0.1     \n",
    "        self.att_w = 0.01\n",
    "        self.criterion = KDLoss(self.feature_loss, self.fcst_loss, self.recon_loss, self.att_loss,  self.feature_w,  self.fcst_w,  self.recon_w,  self.att_w)\n",
    "\n",
    "        print(\"The number of trainable parameters: {}\".format(self.model.count_trainable_params()))\n",
    "        print(\"The number of parameters: {}\".format(self.model.param_num()))\n",
    "        print(self.model)\n",
    "\n",
    "    def train(self, x, y, emb):\n",
    "        self.model.train()\n",
    "        self.optimizer.zero_grad()\n",
    "        ts_enc, prompt_enc, ts_out, prompt_out, ts_att, prompt_att = self.model(x, emb)\n",
    "        loss = self.criterion(ts_enc, prompt_enc, ts_out, prompt_out, ts_att, prompt_att, y)\n",
    "        loss.backward()\n",
    "        if self.clip is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip) \n",
    "        self.optimizer.step() \n",
    "        mse = self.MSE(ts_out, y) \n",
    "        mae = self.MAE(ts_out, y)\n",
    "        return loss.item(), mse.item(), mae.item()\n",
    "\n",
    "    def eval(self, x, y, emb):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            ts_enc, prompt_enc, ts_out, prompt_out, ts_att, prompt_att = self.model(x, emb)\n",
    "            loss = self.criterion(ts_enc, prompt_enc, ts_out, prompt_out, ts_att, prompt_att, y)\n",
    "            mse = self.MSE(ts_out, y)\n",
    "            mae = self.MAE(ts_out, y)\n",
    "        return loss.item(), mse.item(), mae.item()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bde90d8b-ed0a-4f6e-a504-5b279baa3d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--device\", type=str, default=\"cuda:6\", help=\"\")\n",
    "    parser.add_argument(\"--data_path\", type=str, default=\"ETTh1\", help=\"data path\")\n",
    "    parser.add_argument(\"--channel\", type=int, default=512, help=\"number of features\")\n",
    "    parser.add_argument(\"--num_nodes\", type=int, default=7, help=\"number of nodes\")\n",
    "    parser.add_argument(\"--seq_len\", type=int, default=96, help=\"seq_len\")\n",
    "    parser.add_argument(\"--pred_len\", type=int, default=96, help=\"out_len\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=32, help=\"batch size\")\n",
    "    parser.add_argument(\"--lrate\", type=float, default=1e-4, help=\"learning rate\")\n",
    "    parser.add_argument(\"--dropout_n\", type=float, default=0.2, help=\"dropout rate of neural network layers\")\n",
    "    parser.add_argument(\"--d_llm\", type=int, default=768, help=\"hidden dimensions\")\n",
    "    parser.add_argument(\"--e_layer\", type=int, default=1, help=\"layers of transformer encoder\")\n",
    "    parser.add_argument(\"--head\", type=int, default=8, help=\"heads of attention\")\n",
    "    parser.add_argument(\"--model_name\", type=str, default=\"gpt2\", help=\"llm\")\n",
    "    parser.add_argument(\"--weight_decay\", type=float, default=1e-3, help=\"weight decay rate\")\n",
    "    parser.add_argument(\"--feature_w\", type=float, default=0.01, help=\"weight of feature kd loss\")\n",
    "    parser.add_argument(\"--fcst_w\", type=float, default=1, help=\"weight of forecast loss\")\n",
    "    parser.add_argument(\"--recon_w\", type=float, default=0.5, help=\"weight of reconstruction loss\")\n",
    "    parser.add_argument(\"--att_w\", type=float, default=0.01, help=\"weight of attention kd loss\")\n",
    "    parser.add_argument('--num_workers', type=int, default=10, help='data loader num workers')\n",
    "    parser.add_argument(\"--epochs\", type=int, default=100, help=\"\")\n",
    "    parser.add_argument('--seed', type=int, default=2036, help='random seed')\n",
    "    parser.add_argument(\n",
    "        \"--es_patience\",\n",
    "        type=int,\n",
    "        default=50,\n",
    "        help=\"quit if no improvement after this many iterations\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--save\",\n",
    "        type=str,\n",
    "        default=\"./logs/\" + str(time.strftime(\"%Y-%m-%d-%H:%M:%S\")) + \"-\",\n",
    "        help=\"save path\",\n",
    "    )\n",
    "    return parser.parse_args()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf89f7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(args):\n",
    "    data_map = {\n",
    "        'ETTh1': Dataset_ETT_hour,\n",
    "        'ETTh2': Dataset_ETT_hour,\n",
    "        'ETTm1': Dataset_ETT_minute,\n",
    "        'ETTm2': Dataset_ETT_minute\n",
    "        }\n",
    "    data_class = data_map.get(args.data_path, Dataset_Custom)\n",
    "    train_set = data_class(flag='train', scale=True, size=[args.seq_len, 0, args.pred_len], data_path=args.data_path)\n",
    "    val_set = data_class(flag='val', scale=True, size=[args.seq_len, 0, args.pred_len], data_path=args.data_path)\n",
    "    test_set = data_class(flag='test', scale=True, size=[args.seq_len, 0, args.pred_len], data_path=args.data_path)\n",
    "    \n",
    "    scaler = train_set.scaler\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=args.batch_size, shuffle=False, drop_last=True, num_workers=args.num_workers)\n",
    "    val_loader = DataLoader(val_set, batch_size=args.batch_size, shuffle=False, drop_last=True, num_workers=args.num_workers)\n",
    "    test_loader = DataLoader(test_set, batch_size=1, shuffle=False, drop_last=False, num_workers=args.num_workers)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1260332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9157a2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_provider\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loader_emb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset_ETT_hour \u001b[38;5;66;03m#, Dataset_ETT_minute, Dataset_Custom\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mTimeKD\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dual\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkd_loss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KDLoss\n",
      "File \u001b[0;32m~/004_TimeKD/TimeKD/data_provider/data_loader_emb.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "from data_provider.data_loader_emb import Dataset_ETT_hour #, Dataset_ETT_minute, Dataset_Custom\n",
    "from model.TimeKD import Dual\n",
    "from utils.kd_loss import KDLoss\n",
    "from utils.metrics import MSE, MAE, metric\n",
    "import faulthandler\n",
    "faulthandler.enable()\n",
    "torch.cuda.empty_cache()\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:150\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e058a880-7811-461c-8ba2-20c6e18f455b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01margparse\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[43mparse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 33\u001b[0m, in \u001b[0;36mparse_args\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m parser\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--seed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2036\u001b[39m, help\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom seed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m parser\u001b[38;5;241m.\u001b[39madd_argument(\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--es_patience\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m     27\u001b[0m     default\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m     28\u001b[0m     help\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquit if no improvement after this many iterations\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     30\u001b[0m parser\u001b[38;5;241m.\u001b[39madd_argument(\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--save\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m---> 33\u001b[0m     default\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./logs/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mtime\u001b[49m\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     34\u001b[0m     help\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave path\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mparse_args()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "args = parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba43091e-0c70-44d7-8b8f-2d77ac061f74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc21dd10-5a83-4397-a038-4cd9cfbeed4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
