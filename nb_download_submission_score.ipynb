{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f25a1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# log_type = 'test'\n",
    "# df = pd.read_csv(f\"experiment_log_{log_type}.csv\")\n",
    "\n",
    "# df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57a4d001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(f'./experiment_log_{log_type}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "173690f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kaggle\n",
    "# from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# # Authenticate\n",
    "# api = KaggleApi()\n",
    "# api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "320ad6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from datetime import datetime\n",
    "# import pytz\n",
    "\n",
    "# # 1. Define the Singapore Timezone\n",
    "# sg_tz = pytz.timezone('Asia/Singapore')\n",
    "\n",
    "# # 2. Your date string in 'yyyy-mm-dd hh:mm:ss' format\n",
    "# # Note: I corrected 'hh:ss:hh' to 'hh:mm:ss' (hours:minutes:seconds)\n",
    "# date_string = '2026-01-18 00:00:00'\n",
    "\n",
    "# # 3. Parse the string into a naive datetime object\n",
    "# naive_date = datetime.strptime(date_string, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# # 4. Localize it to Singapore Time, then convert to UTC\n",
    "# # This ensures the comparison with Kaggle (UTC) is accurate\n",
    "# cutoff_date_sg = sg_tz.localize(naive_date)\n",
    "# cutoff_date_utc = cutoff_date_sg.astimezone(pytz.UTC)\n",
    "# cutoff_date_naive = cutoff_date_utc.replace(tzinfo=None)\n",
    "# print(cutoff_date_naive)\n",
    "\n",
    "# # The competition ID/slug from the URL (e.g., 'titanic')\n",
    "# comp_name = 'amex-default-prediction'\n",
    "\n",
    "# # Retrieve submissions\n",
    "# submissions = api.competition_submissions(comp_name)\n",
    "\n",
    "# # Convert the list of submission objects into a Pandas DataFrame\n",
    "# # Each object has attributes like 'ref', 'date', 'description', 'status', 'publicScore', 'privateScore'\n",
    "# data = []\n",
    "# for sub in submissions:\n",
    "#     if sub.date > cutoff_date_naive:\n",
    "#         data.append({\n",
    "#             'date': sub.date,\n",
    "#             'description': sub.description,\n",
    "#             'status': sub.status,\n",
    "#             'public_score': sub.public_score,\n",
    "#             'private_score': sub.private_score\n",
    "#         })\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# # Save to CSV\n",
    "# df.to_csv('my_kaggle_submissions.csv', index=False)\n",
    "# df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f16dac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import pandas as pd\n",
    "\n",
    "# # 1. Convert the description string into a Python dictionary/list\n",
    "# # We use a lambda to handle potential nulls or malformed strings safely\n",
    "# def parse_json(x):\n",
    "#     try:\n",
    "#         data = json.loads(x)\n",
    "#         # If the JSON is wrapped in a list [{}], take the first element\n",
    "#         return data[0] if isinstance(data, list) else data\n",
    "#     except:\n",
    "#         return {}\n",
    "\n",
    "# # 2. Apply the parsing logic\n",
    "# json_struct = df['description'].apply(parse_json)\n",
    "\n",
    "# # 3. Create a new DataFrame from the JSON objects and join it back\n",
    "# df_expanded = pd.json_normalize(json_struct)\n",
    "\n",
    "# # 4. Combine with your original stats\n",
    "# # We drop the original 'description' to keep it clean\n",
    "# final_df = pd.concat([df.drop(columns=['description']), df_expanded], axis=1)\n",
    "\n",
    "# final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14219521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# Authenticate\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "249c2215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "def download_sub(date_string = '2026-01-18 06:00:00' ):\n",
    "    # --- 1. Setup Cutoff (Example for Jan 17, 2026 SGT) ---\n",
    "    sg_tz = pytz.timezone('Asia/Singapore')\n",
    "    naive_date = datetime.strptime(date_string, '%Y-%m-%d %H:%M:%S')\n",
    "    cutoff_date_utc = sg_tz.localize(naive_date).astimezone(pytz.UTC).replace(tzinfo=None)\n",
    "\n",
    "    # --- 2. Fetch and Process ---\n",
    "    submissions = api.competition_submissions('amex-default-prediction')\n",
    "    processed_rows = []\n",
    "\n",
    "    for sub in submissions:\n",
    "        if sub.date > cutoff_date_utc:\n",
    "            try:\n",
    "                # Parse the JSON from the description\n",
    "                desc_raw = json.loads(sub.description)\n",
    "                # Handle list-wrapped JSON: [{\"key\": \"val\"}]\n",
    "                desc_dict = desc_raw[0] if isinstance(desc_raw, list) else desc_raw\n",
    "                \n",
    "                # --- 3. RECONSTRUCT ROW IN JSON ORDER ---\n",
    "                row = {}\n",
    "                for key in desc_dict.keys():\n",
    "                    if key == 'public_score':\n",
    "                        # Use the official API score in the JSON's 'public_score' slot\n",
    "                        row[key] = sub.public_score\n",
    "                    elif key == 'private_score':\n",
    "                        # Use the official API score in the JSON's 'private_score' slot\n",
    "                        row[key] = sub.private_score\n",
    "                    else:\n",
    "                        # Keep the original JSON value for all other keys\n",
    "                        row[key] = desc_dict[key]\n",
    "                \n",
    "                # Safety check: if the JSON didn't actually contain the score keys,\n",
    "                # you can optionally append them here:\n",
    "                if 'public_score' not in row: row['public_score'] = sub.public_score\n",
    "                if 'private_score' not in row: row['private_score'] = sub.private_score\n",
    "\n",
    "                processed_rows.append(row)\n",
    "                \n",
    "            except Exception as e:\n",
    "                # Skip rows where description is not valid JSON\n",
    "                continue\n",
    "\n",
    "    # --- 4. Create DataFrame ---\n",
    "    # Since Python 3.7+, dictionaries preserve insertion order, \n",
    "    # and Pandas will honor the order of the keys from the first row.\n",
    "    final_df = pd.DataFrame(processed_rows)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bee62678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_specs</th>\n",
       "      <th>log_time</th>\n",
       "      <th>feature_w</th>\n",
       "      <th>fcst_w</th>\n",
       "      <th>recon_w</th>\n",
       "      <th>att_w</th>\n",
       "      <th>lr</th>\n",
       "      <th>sampling</th>\n",
       "      <th>data_type</th>\n",
       "      <th>seed</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>es_patience</th>\n",
       "      <th>is_predict</th>\n",
       "      <th>amex_metric</th>\n",
       "      <th>AUC</th>\n",
       "      <th>test_start_time</th>\n",
       "      <th>test_end_time</th>\n",
       "      <th>test_duration</th>\n",
       "      <th>public_score</th>\n",
       "      <th>private_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>original_10pct_0.001_42_128_3_512_1_0.2_1.0_1e...</td>\n",
       "      <td>2026-01-21 04:32:14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10pct</td>\n",
       "      <td>original</td>\n",
       "      <td>42</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-21 04:24:52</td>\n",
       "      <td>2026-01-21 04:32:14</td>\n",
       "      <td>442075</td>\n",
       "      <td>0.37676</td>\n",
       "      <td>0.37863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>original_10pct_0.001_42_128_3_512_1_0.2_1e-06_...</td>\n",
       "      <td>2026-01-21 04:24:58</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10pct</td>\n",
       "      <td>original</td>\n",
       "      <td>42</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-21 04:16:35</td>\n",
       "      <td>2026-01-21 04:24:58</td>\n",
       "      <td>502629</td>\n",
       "      <td>0.71397</td>\n",
       "      <td>0.72100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model_specs             log_time  \\\n",
       "46  original_10pct_0.001_42_128_3_512_1_0.2_1.0_1e...  2026-01-21 04:32:14   \n",
       "47  original_10pct_0.001_42_128_3_512_1_0.2_1e-06_...  2026-01-21 04:24:58   \n",
       "\n",
       "    feature_w    fcst_w   recon_w     att_w     lr sampling data_type  seed  \\\n",
       "46   1.000000  0.000001  0.000001  0.000001  0.001    10pct  original    42   \n",
       "47   0.000001  0.000001  1.000000  0.000001  0.001    10pct  original    42   \n",
       "\n",
       "    batch_size  es_patience  is_predict amex_metric   AUC  \\\n",
       "46         128            3        True        None  None   \n",
       "47         128            3        True        None  None   \n",
       "\n",
       "        test_start_time        test_end_time  test_duration public_score  \\\n",
       "46  2026-01-21 04:24:52  2026-01-21 04:32:14         442075      0.37676   \n",
       "47  2026-01-21 04:16:35  2026-01-21 04:24:58         502629      0.71397   \n",
       "\n",
       "   private_score  \n",
       "46       0.37863  \n",
       "47       0.72100  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = download_sub(date_string = '2026-01-19 05:00:00' )\n",
    "final_df = final_df.dropna(subset=['feature_w'])\n",
    "final_df.to_csv(f'./experiment_log_submission.csv',index=False)\n",
    "final_df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecedf028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 20)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "045b5197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fcst_w</th>\n",
       "      <th>feature_w</th>\n",
       "      <th>recon_w</th>\n",
       "      <th>att_w</th>\n",
       "      <th>avg_private_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.737397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.737167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.737997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.737810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.337083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.731247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.725673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.735280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fcst_w  feature_w   recon_w     att_w  avg_private_score\n",
       "7  1.000000   0.000001  1.000000  1.000000           0.737397\n",
       "6  1.000000   0.000001  1.000000  0.000000           0.737167\n",
       "5  1.000000   0.000001  0.000001  1.000000           0.737997\n",
       "4  1.000000   0.000001  0.000001  0.000001           0.737810\n",
       "3  0.000001   1.000000  0.000001  0.000001           0.337083\n",
       "2  0.000001   0.000001  1.000000  1.000000           0.731247\n",
       "1  0.000001   0.000001  1.000000  0.000001           0.725673\n",
       "0  0.000001   0.000001  0.000001  1.000000           0.735280"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Ensure numeric type\n",
    "final_df['private_score'] = pd.to_numeric(final_df['private_score'], errors='coerce')\n",
    "\n",
    "# 2. Get top 3, drop inner index, mean, and convert to named DataFrame\n",
    "top_3_avg = (final_df.groupby(['feature_w', 'fcst_w', 'recon_w', 'att_w'])['private_score']\n",
    "             .nlargest(3)\n",
    "             .reset_index(level=-1, drop=True)\n",
    "             .groupby(['fcst_w','feature_w','recon_w','att_w'])\n",
    "             .mean()\n",
    "             .reset_index(name='avg_private_score'))\n",
    "\n",
    "top_3_avg.sort_values(by=['fcst_w','feature_w','recon_w','att_w'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7cc1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab9c805",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amex__TimeKD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
